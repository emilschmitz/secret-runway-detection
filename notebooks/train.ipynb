{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Landing Strip Detection Training Pipeline\n",
    "\n",
    "\n",
    "\n",
    " This notebook implements a training pipeline for detecting landing strips using satellite imagery. The pipeline includes:\n",
    "\n",
    "\n",
    "\n",
    " - Loading input landing strip data.\n",
    "\n",
    " - Creating input areas around the landing strips.\n",
    "\n",
    " - Downloading Sentinel-2 imagery from Google Earth Engine.\n",
    "\n",
    " - Preparing a dataset for training.\n",
    "\n",
    " - Loading the Geo Foundation Model (GFM) for transfer learning.\n",
    "\n",
    " - Setting up a training loop with Weights & Biases (wandb) logging.\n",
    "\n",
    "\n",
    "\n",
    " **Note**: Ensure that you have authenticated with Google Earth Engine (GEE) using `ee.Authenticate()` and have initialized it with `ee.Initialize()`. Also, make sure `train_utils.py` is in your working directory or Python path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *TODO*\n",
    "* Max value of model outputs can be rather small (in one case, 0.6244). This leads to binary search setting threshold lower, predicting all zeroes\n",
    "* (buffered_labels.float() == 1).float()\n",
    "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
    "(buffered_labels.float() == 1).float().mean()\n",
    "tensor(0.2678) **(!!!)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module named 'google.colab'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import wandb\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import timm  # PyTorch Image Models library\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import re\n",
    "from torcheval.metrics.functional import binary_accuracy\n",
    "\n",
    "# If on Google colab, chdir to /content/drive/MyDrive/Secret_Runway_Detection\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    # Copy the 'Secret Runway Detection Challenge' folder to Colab local storage\n",
    "    !cp -r '/content/drive/MyDrive/Secret Runway Detection Challenge/colab-stuff/' '/content/'\n",
    "    # Change the current working directory to the notebooks folder in local storage\n",
    "    os.chdir('/content/colab-stuff/notebooks')\n",
    "    USING_COLAB = True\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    USING_COLAB = False\n",
    "\n",
    "# Add the src directory to the sys.path\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# Import functions and constants from train_utils\n",
    "from secret_runway_detection.model import (\n",
    "    SegmentationHead,\n",
    "    CombinedModel,\n",
    ")\n",
    "from secret_runway_detection.dataset import LandingStripDataset, SegmentationTransform\n",
    "from secret_runway_detection.train_utils import (\n",
    "    add_buffer_to_label,\n",
    "    RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2. Configuration and Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7a11ed424560>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# Debug flag: Set to True to run on CPU, False to use GPU if available\n",
    "# With DEBUG == True, test and train sets are reduced to 10 samples each\n",
    "DEBUG = True\n",
    "\n",
    "TRAINING_DATASET = 'cross'\n",
    "TRAIN_PERCENTAGE = 0.8\n",
    "\n",
    "# Number of epochs to train for\n",
    "NUM_EPOCHS = 10 if not DEBUG else 2  # Adjust as needed\n",
    "\n",
    "BATCH_SIZE = 32 if USING_COLAB else 4\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cpu') if DEBUG else torch.device(\n",
    "    'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "# logging.getLogger('secret_runway_detection.train_utils').setLevel(logging.DEBUG)\n",
    "logging.getLogger('secret_runway_detection.train_utils').setLevel(logging.INFO)\n",
    "\n",
    "# Initialize wandb\n",
    "wandb.init(project='secret-runway-detection',\n",
    "           mode='online' if not DEBUG else 'dryrun',\n",
    "           dir='..',\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 5. Load Data into Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files: 1579\n",
      "Total strips: 113\n",
      "Training files: 1259\n",
      "Testing files: 320\n"
     ]
    }
   ],
   "source": [
    "train_dir = Path(f'../training_data_{TRAINING_DATASET}')\n",
    "\n",
    "images_dir = train_dir / 'images'\n",
    "labels_dir = train_dir / 'labels'\n",
    "\n",
    "# Get all filenames in the images directory\n",
    "all_filenames = os.listdir(images_dir)\n",
    "\n",
    "# Initialize dictionaries and lists\n",
    "strip_to_files = {}        # For files with strip numbers\n",
    "possibly_empty_files = []  # For 'possibly_empty' files\n",
    "\n",
    "# Regular expression pattern to match filenames with strip numbers\n",
    "pattern = re.compile(r'^area_\\d+_of_strip_(\\d+)\\.npy$')\n",
    "\n",
    "# Process filenames\n",
    "for filename in all_filenames:\n",
    "    if 'possibly_empty' in filename:\n",
    "        # This is a 'possibly_empty' file\n",
    "        possibly_empty_files.append(filename)\n",
    "    else:\n",
    "        # Try to match the pattern to extract strip number\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            strip_number = int(match.group(1))\n",
    "            # Add filename to the list for this strip number\n",
    "            strip_to_files.setdefault(strip_number, []).append(filename)\n",
    "        else:\n",
    "            print(f\"Filename does not match expected pattern: {filename}\")\n",
    "\n",
    "# List of all unique strip numbers\n",
    "strip_numbers = list(strip_to_files.keys())\n",
    "\n",
    "# Shuffle strip numbers for random splitting\n",
    "random.seed(RANDOM_SEED)  # Ensure reproducibility\n",
    "random.shuffle(strip_numbers)\n",
    "\n",
    "# Calculate split index for strips\n",
    "num_strips = len(strip_numbers)\n",
    "split_index = int(num_strips * TRAIN_PERCENTAGE)\n",
    "\n",
    "# Split strip numbers into train and test sets\n",
    "train_strip_numbers = strip_numbers[:split_index]\n",
    "val_strip_numbers = strip_numbers[split_index:]\n",
    "\n",
    "# Collect filenames for train and test sets based on strip numbers\n",
    "train_files = []\n",
    "for strip_num in train_strip_numbers:\n",
    "    train_files.extend(strip_to_files[strip_num])\n",
    "\n",
    "val_files = []\n",
    "for strip_num in val_strip_numbers:\n",
    "    val_files.extend(strip_to_files[strip_num])\n",
    "\n",
    "# Now handle the 'possibly_empty' files\n",
    "# Shuffle the possibly_empty files\n",
    "random.shuffle(possibly_empty_files)\n",
    "\n",
    "# Calculate split index for possibly_empty files\n",
    "num_possibly_empty = len(possibly_empty_files)\n",
    "split_index_empty = int(num_possibly_empty * TRAIN_PERCENTAGE)\n",
    "\n",
    "# Split possibly_empty files into train and test sets\n",
    "train_possibly_empty_files = possibly_empty_files[:split_index_empty]\n",
    "val_possibly_empty_files = possibly_empty_files[split_index_empty:]\n",
    "\n",
    "# Add the possibly_empty files to the train and test file lists\n",
    "train_files.extend(train_possibly_empty_files)\n",
    "val_files.extend(val_possibly_empty_files)\n",
    "\n",
    "# Output some information\n",
    "print(f\"Total files: {len(all_filenames)}\")\n",
    "print(f\"Total strips: {len(strip_numbers)}\")\n",
    "print(f\"Training files: {len(train_files)}\")\n",
    "print(f\"Testing files: {len(val_files)}\")\n",
    "\n",
    "# Define your transform if you have one; otherwise, set to None\n",
    "segmentation_transform = None  # Replace with your actual transform if any\n",
    "\n",
    "# Create train dataset\n",
    "train_dataset = LandingStripDataset(\n",
    "    images_dir=images_dir,\n",
    "    labels_dir=labels_dir,\n",
    "    file_list=train_files,\n",
    "    transform=segmentation_transform\n",
    ")\n",
    "\n",
    "# Create test dataset\n",
    "val_dataset = LandingStripDataset(\n",
    "    images_dir=images_dir,\n",
    "    labels_dir=labels_dir,\n",
    "    file_list=val_files,\n",
    "    transform=segmentation_transform\n",
    ")\n",
    "\n",
    "if DEBUG:\n",
    "    train_dataset.samples = train_dataset.samples[:40]\n",
    "    val_dataset.samples = val_dataset.samples[:10]\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: 5\n",
      "After layer 1: Output size = 10\n",
      "After layer 2: Output size = 20\n",
      "After layer 3: Output size = 40\n",
      "After layer 4: Output size = 80\n",
      "After layer 5: Output size = 160\n",
      "After layer 6: Output size = 320\n"
     ]
    }
   ],
   "source": [
    "# Python code to calculate the output size before interpolation\n",
    "\n",
    "# Initialize input size\n",
    "H_in = 5\n",
    "print(f\"Input size: {H_in}\")\n",
    "\n",
    "# Define the decoder layers\n",
    "layers = [\n",
    "    {'kernel_size': 4, 'stride': 2, 'padding': 1},  # Layer 1\n",
    "    {'kernel_size': 4, 'stride': 2, 'padding': 1},  # Layer 2\n",
    "    {'kernel_size': 4, 'stride': 2, 'padding': 1},  # Layer 3\n",
    "    {'kernel_size': 4, 'stride': 2, 'padding': 1},  # Layer 4\n",
    "    {'kernel_size': 4, 'stride': 2, 'padding': 1},  # Layer 5\n",
    "    {'kernel_size': 4, 'stride': 2, 'padding': 1},  # Layer 6\n",
    "]\n",
    "\n",
    "# Calculate output size after each layer\n",
    "for idx, layer in enumerate(layers):\n",
    "    kernel_size = layer['kernel_size']\n",
    "    stride = layer['stride']\n",
    "    padding = layer['padding']\n",
    "    H_out = (H_in - 1) * stride - 2 * padding + kernel_size\n",
    "    print(f\"After layer {idx+1}: Output size = {H_out}\")\n",
    "    H_in = H_out  # Update input size for next layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 6. Load the Geo Foundation Model (GFM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yacs in /home/emil/Desktop/secret-runway-detection/.venv/lib/python3.12/site-packages (0.1.8)\n",
      "Requirement already satisfied: PyYAML in /home/emil/Desktop/secret-runway-detection/.venv/lib/python3.12/site-packages (from yacs) (6.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1086553/2131875498.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded and moved to device cpu.\n"
     ]
    }
   ],
   "source": [
    "def load_gfm_model(model_path):\n",
    "    \"\"\"\n",
    "    Loads the Geo Foundation Model (GFM) from a checkpoint.\n",
    "\n",
    "    Parameters:\n",
    "    - model_path (str): Path to the model checkpoint.\n",
    "\n",
    "    Returns:\n",
    "    - model (torch.nn.Module): Loaded model.\n",
    "    \"\"\"\n",
    "    model = timm.create_model(\n",
    "        'swin_base_patch4_window7_224',\n",
    "        pretrained=False,\n",
    "        num_classes=0,  # Assuming binary classification\n",
    "    ).to(device)\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "\n",
    "    # Extract the state dictionary\n",
    "    if 'model' in checkpoint:\n",
    "        state_dict = checkpoint['model']\n",
    "    else:\n",
    "        state_dict = checkpoint\n",
    "\n",
    "    # Clean the state dictionary (remove 'module.' prefix if present)\n",
    "    new_state_dict = {}\n",
    "    for k, v in state_dict.items():\n",
    "        if k.startswith('module.'):\n",
    "            new_state_dict[k[len('module.'):]] = v\n",
    "        else:\n",
    "            new_state_dict[k] = v\n",
    "\n",
    "    # Load the state dictionary\n",
    "    model.load_state_dict(new_state_dict, strict=False)\n",
    "    model = model.to(device)\n",
    "    print(f\"Model loaded and moved to device {device}.\")\n",
    "    return model.to(device)\n",
    "\n",
    "! pip install yacs\n",
    "\n",
    "# Path to the pre-trained GFM model\n",
    "# Replace with your actual model path\n",
    "backbone_model_path = '../simmim_pretrain/gfm.pth'\n",
    "\n",
    "# Load the model\n",
    "backbone_model = load_gfm_model(backbone_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. Add Segmentation Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_head = SegmentationHead()\n",
    "\n",
    "model = CombinedModel(backbone_model, segmentation_head).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 7. Define Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "# Suitable for binary classification with logits\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Optionally, define a learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in backbone_model.named_parameters():\n",
    "    if not param.requires_grad:\n",
    "        print(f\"{name}: requires_grad={param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 8. Training Loop with wandb Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch 10] Training Loss: 0.6757\n",
      "Epoch 1 Validation Loss: 0.7338\n",
      "[Epoch 2, Batch 10] Training Loss: 0.6608\n",
      "Epoch 2 Validation Loss: 0.7215\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "# Before the training loop, watch the model\n",
    "wandb.watch(model, criterion=criterion, log=\"all\", log_freq=10)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.squeeze(1)  # Adjust dimensions if necessary\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Log every 10 batches or last batch\n",
    "        if (i + 1) % 10 == 0 or i == len(train_dataloader):\n",
    "            avg_loss = running_loss / 10\n",
    "            print(f\"[Epoch {epoch + 1}, Batch {i + 1}] Training Loss: {avg_loss:.4f}\")\n",
    "\n",
    "            # Log metrics to wandb\n",
    "            wandb.log({\n",
    "                'epoch': epoch + 1,\n",
    "                'batch': i + 1,\n",
    "                'training_loss': avg_loss,\n",
    "                'learning_rate': optimizer.param_groups[0]['lr']\n",
    "            })\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.squeeze(1)  # Adjust dimensions if necessary\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Accumulate validation loss\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    print(f\"Epoch {epoch + 1} Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # Log validation loss to wandb\n",
    "    wandb.log({\n",
    "        'epoch': epoch + 1,\n",
    "        'validation_loss': avg_val_loss\n",
    "    })\n",
    "\n",
    "    # Step the scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1. Find accuracy-optimizing thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 9. Save the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize W&B run if not already initialized\n",
    "wandb.init(project='your_project_name')\n",
    "\n",
    "# Create a 'checkpoints' directory within the current directory\n",
    "os.makedirs('../checkpoints', exist_ok=True)\n",
    "\n",
    "# Define the model save path within the 'checkpoints' directory\n",
    "model_save_path = f'../checkpoints/{wandb.run.name}.pth'\n",
    "\n",
    "# Save the model's state_dict\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Model saved to '{model_save_path}'.\")\n",
    "\n",
    "# Create a W&B Artifact for the model\n",
    "artifact = wandb.Artifact('model', type='model')\n",
    "\n",
    "# Add the saved model file to the artifact\n",
    "artifact.add_file(model_save_path)\n",
    "\n",
    "# Log the artifact to W&B\n",
    "wandb.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 10. Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "# Training Summary\n",
    "\n",
    "- **Model**: Swin Transformer (GFM) loaded from pre-trained checkpoint.\n",
    "- **Dataset**: Landing strips with Sentinel-2 imagery.\n",
    "- **Loss Function**: BCEWithLogitsLoss.\n",
    "- **Optimizer**: Adam with learning rate scheduler.\n",
    "- **Logging**: Weights & Biases (wandb) for experiment tracking.\n",
    "- **Device**: {}\n",
    "- **Epochs**: {}\n",
    "\n",
    "Training has been completed and the model has been saved.\n",
    "\"\"\".format(device, NUM_EPOCHS))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
