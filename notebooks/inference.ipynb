{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Things to try to increase LB score\n",
    "\n",
    " 1. Change way in which buffer region is constucted (Cross, Square, Ball)\n",
    "\n",
    " 1. Change submission csv method to transpose rows and cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Submitting first 200 000, we have\n",
    "\n",
    " * 0.025533852 accuracy with only zeros.\n",
    "\n",
    " * 0.00043453 accuracy with only ones.\n",
    "\n",
    " * ie, 0.00043453 / (0.00043453 + 0.025533852) = 0.01673304097 ~= **1.67 %** rate of ones\n",
    "\n",
    "\n",
    "\n",
    " ....We should maybe consider that when setting threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Estimated time for getting **25m rows**:\n",
    "\n",
    " * One forward pass gives 40 000 rows\n",
    "\n",
    " * One forward pass takes approx. 0.5 sec\n",
    "\n",
    " * 25m / 40 000 = 625\n",
    "\n",
    " * 625 * 0.5 ~= 300 sec = **5 min**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Inference Notebook\n",
    "\n",
    "\n",
    "\n",
    " This notebook performs inference on test AOIs using the trained model. It reads the AOIs from shapefiles, processes each AOI through the model, and aggregates the results into final prediction tensors. The predictions are then converted into submission CSV files.\n",
    "\n",
    "\n",
    "\n",
    " The methods from `inference_utils.py` and `train_utils.py` are imported and used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import os\n",
    "import sys\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyproj\n",
    "import torch\n",
    "from shapely.geometry import Polygon, Point\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import re \n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Add the src directory to the sys.path\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# Import functions and constants from inference_utils and train_utils\n",
    "from secret_runway_detection.inference_utils import (\n",
    "    aoi_to_tiles,\n",
    "    aoi_to_input_areas,\n",
    "    pad_output_tensor,\n",
    "    run_inference_on_aoi,\n",
    "    tensor_to_submission_csv,\n",
    "    fetch_and_stitch_aoi_quarters,\n",
    ")\n",
    "\n",
    "from secret_runway_detection.train_utils import (\n",
    "    input_area_to_input_image,\n",
    "    make_input_image_tensor\n",
    ")\n",
    "\n",
    "from secret_runway_detection.model import CombinedModel\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# Set up device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Configuration Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "\n",
    "# Tile and AOI parameters\n",
    "TILE_SIDE_LEN = 10.0  # in meters\n",
    "AOI_HEIGHT = 15270.0  # in meters\n",
    "AOI_WIDTH = 15410.0   # in meters\n",
    "\n",
    "ROWS_COUNT = 1527  # Number of tile rows\n",
    "COLUMNS_COUNT = 1541  # Number of tile columns\n",
    "\n",
    "assert (TILE_SIDE_LEN == AOI_HEIGHT / ROWS_COUNT) and (TILE_SIDE_LEN == AOI_WIDTH / COLUMNS_COUNT)\n",
    "\n",
    "# Model input and output dimensions\n",
    "INPUT_IMAGE_HEIGHT = 224  # in pixels\n",
    "INPUT_IMAGE_WIDTH = 224\n",
    "\n",
    "TILES_PER_AREA_LEN = 200  # Number of tiles per side in one input area\n",
    "\n",
    "# Number of input areas to cover the AOI\n",
    "INPUT_AREAS_VERTICALLY = 10\n",
    "INPUT_AREAS_HORIZONTALLY = 10\n",
    "\n",
    "# Threshold for converting model outputs to binary predictions\n",
    "THRESHOLD = 0.5  # Adjust based on validation performance\n",
    "\n",
    "# Path to the trained model checkpoint\n",
    "MODEL_CHECKPOINT_PATH = 'checkpoints/model_checkpoint.pth'  # Update this path\n",
    "\n",
    "# Path to save the submission CSVs\n",
    "SUBMISSION_CSV_DIR = 'submission_csvs'\n",
    "os.makedirs(SUBMISSION_CSV_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Load the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "CombinedModel.__init__() missing 2 required positional arguments: 'backbone' and 'segmentation_head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load model checkpoint from ../checkpoints dir\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mCombinedModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(MODEL_CHECKPOINT_PATH))\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mTypeError\u001b[0m: CombinedModel.__init__() missing 2 required positional arguments: 'backbone' and 'segmentation_head'"
     ]
    }
   ],
   "source": [
    "# Load model checkpoint from ../checkpoints dir\n",
    "model = torch.load(MODEL_CHECKPOINT_PATH)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load images of AOIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing AOI: aoi_2021_04\n",
      "Mosaic image loaded for AOI: aoi_2021_04\n",
      "\n",
      "Loaded 1 AOI images into the dictionary.\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## Load AOI Mosaics Based on Shapefile Names and Check for Missing Mosaics\n",
    "\n",
    "# %%\n",
    "import os\n",
    "import rasterio\n",
    "import numpy as np\n",
    "\n",
    "# Directory containing AOI shapefiles\n",
    "AOI_SHAPEFILES_DIR = '../shp_test_AOIs/shp'  # Adjust the path as necessary\n",
    "\n",
    "# Directory where the mosaic images are saved\n",
    "mosaic_images_dir = '../aoi_mosaic_images'  # Adjust the path as necessary\n",
    "\n",
    "# Initialize an empty dictionary to store the images\n",
    "aoi_images_dict = {}\n",
    "\n",
    "# List all shapefiles in the directory\n",
    "aoi_shapefiles = [f for f in os.listdir(AOI_SHAPEFILES_DIR) if f.endswith('.shp')]\n",
    "\n",
    "# Extract AOI IDs from the shapefile names\n",
    "aoi_ids = [os.path.splitext(f)[0] for f in aoi_shapefiles]\n",
    "\n",
    "if DEBUG:\n",
    "    aoi_ids = aoi_ids[:1]  # Limit the number of AOIs to load for debugging\n",
    "\n",
    "# Iterate over each AOI ID and attempt to load the corresponding mosaic\n",
    "for aoi_id in aoi_ids:\n",
    "    mosaic_filename = f'{aoi_id}_mosaic.tif'\n",
    "    mosaic_file_path = os.path.join(mosaic_images_dir, mosaic_filename)\n",
    "    print(f\"Processing AOI: {aoi_id}\")\n",
    "    \n",
    "    # Check if the mosaic file exists\n",
    "    if not os.path.exists(mosaic_file_path):\n",
    "        raise FileNotFoundError(f\"Mosaic file not found for AOI {aoi_id}: {mosaic_file_path}\")\n",
    "    else:\n",
    "        # Open the image using rasterio\n",
    "        with rasterio.open(mosaic_file_path) as src:\n",
    "            # Read the image bands\n",
    "            img_data = src.read()\n",
    "            # Store the image data in the dictionary\n",
    "            aoi_images_dict[aoi_id] = img_data\n",
    "        print(f\"Mosaic image loaded for AOI: {aoi_id}\")\n",
    "\n",
    "print(f\"\\nLoaded {len(aoi_images_dict)} AOI images into the dictionary.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Run Inference on Each AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def run_inference_on_aoi(aoi_gdf: gpd.GeoDataFrame, model: torch.nn.Module, threshold: float) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Runs inference on the given AOI using the provided model.\n",
    "\n",
    "    Parameters:\n",
    "    - aoi_gdf (gpd.GeoDataFrame): GeoDataFrame containing the AOI geometry.\n",
    "    - model (torch.nn.Module): The trained model.\n",
    "    - threshold (float): Threshold for converting model outputs to binary predictions.\n",
    "\n",
    "    Returns:\n",
    "    - final_prediction_tensor (torch.Tensor): The aggregated prediction tensor for the AOI.\n",
    "    \"\"\"\n",
    "    aoi = aoi_gdf.geometry.iloc[0]\n",
    "    crs = aoi_gdf.crs\n",
    "\n",
    "    input_areas = aoi_to_input_areas(aoi, crs)\n",
    "\n",
    "    padded_output_tensors = []\n",
    "    for _, input_area_row in input_areas.iterrows():\n",
    "        input_area = input_area_row['geometry']\n",
    "        idxs = input_area_row['idxs']\n",
    "\n",
    "        # Fetch the input image for the input area\n",
    "        input_image = input_area_to_input_image(\n",
    "            input_area=input_area,\n",
    "            input_area_crs=crs,\n",
    "            input_image_width=INPUT_IMAGE_WIDTH,\n",
    "            input_image_height=INPUT_IMAGE_HEIGHT\n",
    "        )\n",
    "\n",
    "        # If the image is empty, skip this area\n",
    "        if np.all(input_image == 0):\n",
    "            continue\n",
    "\n",
    "        # Convert the input image to a tensor\n",
    "        input_tensor = make_input_image_tensor(input_image)\n",
    "        input_tensor = input_tensor.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output_tensor = model(input_tensor)\n",
    "            output_tensor = output_tensor.squeeze(0).squeeze(0)  # Shape: (H, W)\n",
    "\n",
    "        # Pad the output tensor to the size of the AOI\n",
    "        output_tensor_padded = pad_output_tensor(output_tensor, idxs)\n",
    "        padded_output_tensors.append(output_tensor_padded)\n",
    "\n",
    "    if not padded_output_tensors:\n",
    "        raise ValueError(\"No valid input areas were processed. Check the input data.\")\n",
    "\n",
    "    # Stack and take the maximum confidence for overlapping areas\n",
    "    aoi_confidence = torch.stack(padded_output_tensors, dim=0)\n",
    "    aoi_confidence, _ = torch.max(aoi_confidence, dim=0)\n",
    "\n",
    "    final_prediction_tensor = (aoi_confidence > threshold).float()\n",
    "\n",
    "    return final_prediction_tensor\n",
    "\n",
    "# Now, run inference on each AOI shapefile\n",
    "for shapefile in aoi_shapefiles:\n",
    "    aoi_id = os.path.splitext(shapefile)[0]  # Get the AOI ID from the filename\n",
    "    aoi_shapefile_path = os.path.join(AOI_SHAPEFILES_DIR, shapefile)\n",
    "    print(f\"Processing AOI: {aoi_id}\")\n",
    "\n",
    "    # Read the AOI shapefile\n",
    "    aoi_gdf = gpd.read_file(aoi_shapefile_path)\n",
    "    # Ensure the CRS is correct\n",
    "    if aoi_gdf.crs is None:\n",
    "        # Assign a default CRS if none is set\n",
    "        aoi_gdf.set_crs(epsg=4326, inplace=True)\n",
    "    aoi_gdf = aoi_gdf.to_crs('EPSG:32633')  # Adjust to your working CRS\n",
    "\n",
    "    # Run inference on the AOI\n",
    "    final_prediction_tensor = run_inference_on_aoi(aoi_gdf, model, THRESHOLD)\n",
    "    print(f\"Inference completed on AOI: {aoi_id}\")\n",
    "\n",
    "    # Convert the prediction tensor to submission CSV\n",
    "    submission_df = tensor_to_submission_csv(final_prediction_tensor, indexes='from-top-left', csvs_dir=SUBMISSION_CSV_DIR)\n",
    "    submission_csv_path = os.path.join(SUBMISSION_CSV_DIR, f'submission_{aoi_id}.csv')\n",
    "    submission_df.to_csv(submission_csv_path, index=False)\n",
    "    print(f\"Submission CSV saved to {submission_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# - Ensure that the coordinate reference systems (CRS) are consistent throughout the process.\n",
    "# - Verify the indexing of rows and columns in the `tensor_to_submission_csv` function to match the competition requirements.\n",
    "# - The code assumes that the helper functions are correctly defined in `inference_utils.py` and `train_utils.py`.\n",
    "# - Adjust paths and constants as necessary based on your project structure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "print(\"Inference process completed for all AOIs. Submission files are ready.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
