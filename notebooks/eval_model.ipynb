{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import wandb\n",
    "import timm\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Add the src directory to the sys.path\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from secret_runway_detection.model import CombinedModel, SegmentationHead\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# Set up device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Configuration Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "\n",
    "# BUFFER_TYPE = 'cross'\n",
    "RUN_PATH = 'esedx12/secret-runway-detection/621fojqi'\n",
    "\n",
    "# IS_ON_WANDB = True\n",
    "# RUN_NAME = 'neat-energy-31'\n",
    "# MODEL_NAME = 'model:v7'\n",
    "\n",
    "# # Model input and output dimensions\n",
    "# INPUT_IMAGE_SIDE_LEN_PX = 224  # in pixels\n",
    "# TILES_PER_INPUT_AREA_LEN = 224  # Number of tiles per side in one input area\n",
    "\n",
    "# Threshold for converting model outputs to binary predictions\n",
    "THRESHOLD = 0.5  # Adjust based on validation performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Path to the trained model checkpoint\n",
    "# MODEL_CHECKPOINT_PATH = '../checkpoints/trained_model.pth'  # Update this path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the W&B run\n",
    "train_run = wandb.Api().run(RUN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Load the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model:v7, 358.74MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('../artifacts/neat-energy-31.pth')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from more_itertools import one\n",
    "\n",
    "# Fetch the model artifact from the W&B run\n",
    "artifacts = train_run.logged_artifacts()\n",
    "artifact = one(artifacts)  # Ensures exactly one artifact\n",
    "state_dict_dir = artifact.download(root='../artifacts/')\n",
    "state_dict_dir = Path(state_dict_dir)\n",
    "state_dict_path = state_dict_dir / f'{train_run.name}.pth'\n",
    "state_dict_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model checkpoint from ../checkpoints dir\n",
    "backbone = model = timm.create_model(\n",
    "        'swin_base_patch4_window7_224',\n",
    "        pretrained=False,\n",
    "        num_classes=0,  # Assuming binary classification\n",
    "    )\n",
    "\n",
    "segmentation_head = SegmentationHead()\n",
    "\n",
    "model = CombinedModel(backbone, segmentation_head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3991728/1339217503.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(state_dict_path, map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CombinedModel(\n",
       "  (backbone): SwinTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (layers): Sequential(\n",
       "      (0): SwinTransformerStage(\n",
       "        (downsample): Identity()\n",
       "        (blocks): Sequential(\n",
       "          (0): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.004)\n",
       "            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.004)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): SwinTransformerStage(\n",
       "        (downsample): PatchMerging(\n",
       "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.009)\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.009)\n",
       "          )\n",
       "          (1): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.013)\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.013)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): SwinTransformerStage(\n",
       "        (downsample): PatchMerging(\n",
       "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.017)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.017)\n",
       "          )\n",
       "          (1): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.022)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.022)\n",
       "          )\n",
       "          (2): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.026)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.026)\n",
       "          )\n",
       "          (3): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.030)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.030)\n",
       "          )\n",
       "          (4): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.035)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.035)\n",
       "          )\n",
       "          (5): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.039)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.039)\n",
       "          )\n",
       "          (6): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.043)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.043)\n",
       "          )\n",
       "          (7): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.048)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.048)\n",
       "          )\n",
       "          (8): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.052)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.052)\n",
       "          )\n",
       "          (9): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.057)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.057)\n",
       "          )\n",
       "          (10): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.061)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.061)\n",
       "          )\n",
       "          (11): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.065)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.065)\n",
       "          )\n",
       "          (12): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.070)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.070)\n",
       "          )\n",
       "          (13): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.074)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.074)\n",
       "          )\n",
       "          (14): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.078)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.078)\n",
       "          )\n",
       "          (15): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.083)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.083)\n",
       "          )\n",
       "          (16): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.087)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.087)\n",
       "          )\n",
       "          (17): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.091)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.091)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): SwinTransformerStage(\n",
       "        (downsample): PatchMerging(\n",
       "          (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "          (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.096)\n",
       "            (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.096)\n",
       "          )\n",
       "          (1): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.100)\n",
       "            (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.100)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (head): ClassifierHead(\n",
       "      (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "      (fc): Identity()\n",
       "      (flatten): Identity()\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (fc): Linear(in_features=1024, out_features=6400, bias=True)\n",
       "    (decoder): Sequential(\n",
       "      (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (10): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): ConvTranspose2d(16, 8, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (13): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (14): ReLU(inplace=True)\n",
       "      (15): ConvTranspose2d(8, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Model from WandB, which we saved as state dict\n",
    "model.load_state_dict(torch.load(state_dict_path, map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'best_threshold'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_threshold \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbest_threshold\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'best_threshold'"
     ]
    }
   ],
   "source": [
    "best_threshold = train_run.config['best_threshold']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load validation images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = Path(\n",
    "    f'../training_data/training_data_{train_run.config[\"training_dataset\"]}')\n",
    "\n",
    "images_dir = train_dir / 'images'\n",
    "labels_dir = train_dir / 'labels'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all filenames in the images directory\n",
    "import re\n",
    "\n",
    "\n",
    "all_filenames = os.listdir(images_dir)\n",
    "\n",
    "# Initialize dictionaries and lists\n",
    "strip_to_files = {}        # For files with strip numbers\n",
    "possibly_empty_files = []  # For 'possibly_empty' files\n",
    "\n",
    "# Regular expression pattern to match filenames with strip numbers\n",
    "pattern = re.compile(r'^area_\\d+_of_strip_(\\d+)\\.npy$')\n",
    "\n",
    "# Process filenames\n",
    "for filename in all_filenames:\n",
    "    if 'possibly_empty' in filename:\n",
    "        # This is a 'possibly_empty' file\n",
    "        possibly_empty_files.append(filename)\n",
    "    else:\n",
    "        # Try to match the pattern to extract strip number\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            strip_number = int(match.group(1))\n",
    "            # Add filename to the list for this strip number\n",
    "            strip_to_files.setdefault(strip_number, []).append(filename)\n",
    "        else:\n",
    "            print(f\"Filename does not match expected pattern: {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_strip_numbers = train_run.config['val_strip_numbers']\n",
    "\n",
    "val_files = []\n",
    "for strip_num in val_strip_numbers:\n",
    "    val_files.extend(strip_to_files[strip_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your transform if you have one; otherwise, set to None\n",
    "from dataset import LandingStripDataset\n",
    "\n",
    "\n",
    "segmentation_transform = None  # Replace with your actual transform if any\n",
    "\n",
    "# Create validation dataset\n",
    "val_dataset = LandingStripDataset(\n",
    "    images_dir=images_dir,\n",
    "    labels_dir=labels_dir,\n",
    "    file_list=val_files,\n",
    "    transform=segmentation_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Image, Label and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the model\n",
    "state_dict_path = \"path/to/your/state_dict.pth\"  # Replace with your actual path\n",
    "state_dict = torch.load(state_dict_path, map_location=torch.device('cpu'))\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "\n",
    "# Function to visualize predictions\n",
    "def visualize_predictions(model, dataset, num_samples=5):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(num_samples):\n",
    "            sample = dataset[i]\n",
    "            input_image = sample['image'].unsqueeze(0)  # Add batch dimension\n",
    "            label = sample['label']\n",
    "            \n",
    "            # Generate prediction\n",
    "            prediction = model(input_image).squeeze(0)  # Remove batch dimension\n",
    "            \n",
    "            # Convert tensors to numpy arrays for visualization\n",
    "            input_image_np = input_image.squeeze(0).numpy().transpose(1, 2, 0)  # HWC format\n",
    "            label_np = label.numpy()\n",
    "            prediction_np = prediction.numpy()\n",
    "            \n",
    "            # Plot input image, label, and prediction\n",
    "            fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "            ax[0].imshow(input_image_np)\n",
    "            ax[0].set_title('Input Image')\n",
    "            ax[0].axis('off')\n",
    "            \n",
    "            ax[1].imshow(label_np, cmap='gray')\n",
    "            ax[1].set_title('Label')\n",
    "            ax[1].axis('off')\n",
    "            \n",
    "            ax[2].imshow(prediction_np, cmap='gray')\n",
    "            ax[2].set_title('Prediction')\n",
    "            ax[2].axis('off')\n",
    "            \n",
    "            plt.show()\n",
    "\n",
    "# Visualize predictions for a few samples\n",
    "visualize_predictions(model, val_dataset, num_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize one AOI confidence map and the corresponding image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from skimage.transform import resize\n",
    "import matplotlib.colors as mcolors\n",
    "import torch\n",
    "\n",
    "# Function to normalize and prepare the satellite image for display\n",
    "def prepare_satellite_image(image_data):\n",
    "    # Stack bands into RGB format\n",
    "    img_rgb = np.dstack((image_data[0], image_data[1], image_data[2]))\n",
    "    # Normalize the image for display\n",
    "    img_rgb = img_rgb.astype(float)\n",
    "    img_rgb = (img_rgb - img_rgb.min()) / (img_rgb.max() - img_rgb.min())\n",
    "    return img_rgb\n",
    "\n",
    "# Function to overlay the confidence map on the satellite image\n",
    "def overlay_confidence_map(satellite_image, confidence_map):\n",
    "    print(\"Overlaying confidence map...\")\n",
    "    # Convert confidence_map to NumPy array if it's a PyTorch tensor\n",
    "    if isinstance(confidence_map, torch.Tensor):\n",
    "        confidence_map = confidence_map.detach().cpu().numpy()\n",
    "    \n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.imshow(satellite_image)\n",
    "    plt.title(\"Satellite Image with Confidence Map Overlay\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Resize the confidence map to match the satellite image dimensions\n",
    "    confidence_map_resized = resize(confidence_map, (satellite_image.shape[0], satellite_image.shape[1]),\n",
    "                                    order=1, preserve_range=True, anti_aliasing=False)\n",
    "    \n",
    "    # Create a color map for the confidence map\n",
    "    cmap = plt.cm.Reds\n",
    "    cmap.set_under(color='none')  # Make values below the threshold transparent\n",
    "    \n",
    "    # Define a threshold for visualization\n",
    "    THRESHOLD = 0.5  # Adjust based on your data\n",
    "    \n",
    "    # Overlay the confidence map\n",
    "    plt.imshow(confidence_map_resized, cmap=cmap, alpha=0.5, vmin=THRESHOLD, vmax=1)\n",
    "    \n",
    "    # Add a colorbar\n",
    "    plt.colorbar(label='Confidence Score')\n",
    "    \n",
    "    plt.show()\n",
    "    print(\"Confidence map plot displayed.\")\n",
    "\n",
    "# Function to overlay the has-strip map on the satellite image\n",
    "def overlay_has_strip_map(satellite_image, has_strip_map):\n",
    "    print(\"Overlaying has-strip map...\")\n",
    "    # Convert has_strip_map to NumPy array if it's a PyTorch tensor\n",
    "    if isinstance(has_strip_map, torch.Tensor):\n",
    "        has_strip_map = has_strip_map.detach().cpu().numpy()\n",
    "    \n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.imshow(satellite_image)\n",
    "    plt.title(\"Satellite Image with Has-Strip Map Overlay\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Resize the has-strip map to match the satellite image dimensions\n",
    "    has_strip_map_resized = resize(has_strip_map.astype(float), (satellite_image.shape[0], satellite_image.shape[1]),\n",
    "                                   order=0, preserve_range=True, anti_aliasing=False)\n",
    "    \n",
    "    # Create a colormap for the has-strip map\n",
    "    cmap = mcolors.ListedColormap(['none', 'red'])\n",
    "    bounds = [0, 0.5, 1]\n",
    "    norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "    \n",
    "    # Overlay the has-strip map\n",
    "    plt.imshow(has_strip_map_resized, cmap=cmap, norm=norm, alpha=0.5)\n",
    "    \n",
    "    # Add a legend\n",
    "    legend_elements = [\n",
    "        Patch(facecolor='red', edgecolor='red', label='Has-Strip Area')\n",
    "    ]\n",
    "    plt.legend(handles=legend_elements, loc='lower right')\n",
    "    \n",
    "    plt.show()\n",
    "    print(\"Has-strip map plot displayed.\")\n",
    "\n",
    "# Example usage\n",
    "# Assuming you have 'aoi_image', 'confidence_map', and 'has_strip_map' variables\n",
    "satellite_image = prepare_satellite_image(aoi_image)\n",
    "overlay_confidence_map(satellite_image, confidence_map)\n",
    "overlay_has_strip_map(satellite_image, has_strip_map)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
